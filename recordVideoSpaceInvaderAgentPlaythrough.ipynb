{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sczopek/spaceInvadersAtariRl/blob/main/recordVideoSpaceInvaderAgentPlaythrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzM45utCfbnl",
        "outputId": "bd3605f4-5088-4c0a-d4c7-af1a47a8bc1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3<=2.3.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (2.2.1)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (13.9.4)\n",
            "Requirement already satisfied: shimmy~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]<=2.3.1) (11.0.0)\n",
            "Requirement already satisfied: autorom~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<=2.3.1->stable-baselines3[extra]<=2.3.1) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]<=2.3.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]<=2.3.1) (2.18.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (6.4.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]<=2.3.1) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]<=2.3.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]<=2.3.1) (2024.12.14)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "# stable-baselines3 = 'https://stable-baselines3.readthedocs.io/en/master/index.html'\n",
        "# gymnasium = 'https://gymnasium.farama.org/'\n",
        "\n",
        "!pip install \"stable-baselines3[extra]<=2.3.1\"\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5x_lpUIflTU",
        "outputId": "1b978771-ecb2-43c5-c4ca-b979f803b994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decide which version of Space Invaders to use, noFrameSkip or the default frameSkip version.  If the noFrameSkip version is used, there is an issue of recording all of the sprites.  \n",
        "\n",
        "Some sprites won't be recorded when noFrameSkip is used.  Either the defender's laser sprite will be missing or the invaders' bomb sprites will be missing.  Using SpaceInvaders-v4 is recommended.\n",
        "\n",
        "\n",
        "Special care is needed to extract a single video from the agent model.  For training purposes 8 environments are being played simultaneously (n_envs=8).  Later in the code, video from a single environment will be extracted."
      ],
      "metadata": {
        "id": "7KviDShKQHsa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GLeJq6rftbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caea847-d820-4335-8cfa-7f4c034ab307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:449: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  th_object = th.load(file_content, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "\n",
        "# There already exists an environment generator that will make and wrap atari environments correctly.\n",
        "# env = make_atari_env(\"SpaceInvadersNoFrameskip-v4\", n_envs=8, seed=0)\n",
        "env = make_atari_env(\"SpaceInvaders-v4\", n_envs=8, seed=0)\n",
        "# Stack 4 frames\n",
        "vec_env = VecFrameStack(env, n_stack=4)\n",
        "\n",
        "\n",
        "# model = PPO.load(\"/content/gdrive/MyDrive/models/PPO/ppo_spaceInvadersLvl4Train_63955088_steps\",\n",
        "#                  verbose=1,\n",
        "#                  force_reset=False)\n",
        "model = PPO.load(\"/content/gdrive/MyDrive/models/PPO_try2/ppo_spaceInvadersFrameSkipWinningParams_178798848_steps\",\n",
        "                 verbose=1,\n",
        "                 force_reset=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify Stable-Baselines3::evaluate_policy() function to also return a video recording along with the ep rewards and ep lengths."
      ],
      "metadata": {
        "id": "jWBL1IYVR2xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3.common import type_aliases\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnv, VecMonitor, is_vecenv_wrapped\n",
        "\n",
        "\n",
        "def evaluate_policy_andReturnRecording(\n",
        "    model: \"type_aliases.PolicyPredictor\",\n",
        "    env: Union[gym.Env, VecEnv],\n",
        "    n_eval_episodes: int = 10,\n",
        "    deterministic: bool = True,\n",
        "    render: bool = False,\n",
        "    callback: Optional[Callable[[Dict[str, Any], Dict[str, Any]], None]] = None,\n",
        "    reward_threshold: Optional[float] = None,\n",
        "    return_episode_rewards: bool = False,\n",
        "    warn: bool = True,\n",
        ") -> Union[Tuple[float, float], Tuple[List[float], List[int]]]:\n",
        "    \"\"\"\n",
        "    Runs policy for ``n_eval_episodes`` episodes and returns average reward.\n",
        "    If a vector env is passed in, this divides the episodes to evaluate onto the\n",
        "    different elements of the vector env. This static division of work is done to\n",
        "    remove bias. See https://github.com/DLR-RM/stable-baselines3/issues/402 for more\n",
        "    details and discussion.\n",
        "\n",
        "    .. note::\n",
        "        If environment has not been wrapped with ``Monitor`` wrapper, reward and\n",
        "        episode lengths are counted as it appears with ``env.step`` calls. If\n",
        "        the environment contains wrappers that modify rewards or episode lengths\n",
        "        (e.g. reward scaling, early episode reset), these will affect the evaluation\n",
        "        results as well. You can avoid this by wrapping environment with ``Monitor``\n",
        "        wrapper before anything else.\n",
        "\n",
        "    :param model: The RL agent you want to evaluate. This can be any object\n",
        "        that implements a `predict` method, such as an RL algorithm (``BaseAlgorithm``)\n",
        "        or policy (``BasePolicy``).\n",
        "    :param env: The gym environment or ``VecEnv`` environment.\n",
        "    :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "    :param deterministic: Whether to use deterministic or stochastic actions\n",
        "    :param render: Whether to render the environment or not\n",
        "    :param callback: callback function to do additional checks,\n",
        "        called after each step. Gets locals() and globals() passed as parameters.\n",
        "    :param reward_threshold: Minimum expected reward per episode,\n",
        "        this will raise an error if the performance is not met\n",
        "    :param return_episode_rewards: If True, a list of rewards and episode lengths\n",
        "        per episode will be returned instead of the mean.\n",
        "    :param warn: If True (default), warns user about lack of a Monitor wrapper in the\n",
        "        evaluation environment.\n",
        "    :return: Mean reward per episode, std of reward per episode.\n",
        "        Returns ([float], [int]) when ``return_episode_rewards`` is True, first\n",
        "        list containing per-episode rewards and second containing per-episode lengths\n",
        "        (in number of steps).\n",
        "    \"\"\"\n",
        "    is_monitor_wrapped = False\n",
        "    # Avoid circular import\n",
        "    from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "    if not isinstance(env, VecEnv):\n",
        "        env = DummyVecEnv([lambda: env])  # type: ignore[list-item, return-value]\n",
        "\n",
        "    is_monitor_wrapped = is_vecenv_wrapped(env, VecMonitor) or env.env_is_wrapped(Monitor)[0]\n",
        "\n",
        "    if not is_monitor_wrapped and warn:\n",
        "        warnings.warn(\n",
        "            \"Evaluation environment is not wrapped with a ``Monitor`` wrapper. \"\n",
        "            \"This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. \"\n",
        "            \"Consider wrapping environment first with ``Monitor`` wrapper.\",\n",
        "            UserWarning,\n",
        "        )\n",
        "\n",
        "    n_envs = env.num_envs\n",
        "    episode_rewards = []\n",
        "    episode_lengths = []\n",
        "\n",
        "    # my code for saving images to later make a video\n",
        "    episode_img = [] # episode_img[j] holds all rgb arr images for ep j\n",
        "    # for each env, record all the images until the episode completes\n",
        "    # then when env[envIdx] completes ep, imgRecPerEnv[envIdx] = []\n",
        "    # reseting the memory for the next ep\n",
        "    imgRecPerEnv = [ [] for i in range(n_envs) ]\n",
        "\n",
        "    episode_counts = np.zeros(n_envs, dtype=\"int\")\n",
        "    # Divides episodes among different sub environments in the vector as evenly as possible\n",
        "    episode_count_targets = np.array([(n_eval_episodes + i) // n_envs for i in range(n_envs)], dtype=\"int\")\n",
        "\n",
        "    current_rewards = np.zeros(n_envs)\n",
        "    current_lengths = np.zeros(n_envs, dtype=\"int\")\n",
        "    observations = env.reset()\n",
        "    states = None\n",
        "    episode_starts = np.ones((env.num_envs,), dtype=bool)\n",
        "    while (episode_counts < episode_count_targets).any():\n",
        "        actions, states = model.predict(\n",
        "            observations,  # type: ignore[arg-type]\n",
        "            state=states,\n",
        "            episode_start=episode_starts,\n",
        "            deterministic=deterministic,\n",
        "        )\n",
        "        new_observations, rewards, dones, infos = env.step(actions)\n",
        "        current_rewards += rewards\n",
        "        current_lengths += 1\n",
        "        for i in range(n_envs):\n",
        "            if episode_counts[i] < episode_count_targets[i]:\n",
        "                # unpack values so that the callback can access the local variables\n",
        "                reward = rewards[i]\n",
        "                done = dones[i]\n",
        "                info = infos[i]\n",
        "                episode_starts[i] = done\n",
        "\n",
        "                # my code to capture each img frame from each env\n",
        "                img = env.get_images()[i]\n",
        "                imgRecPerEnv[i].append(img)\n",
        "\n",
        "                if callback is not None:\n",
        "                    callback(locals(), globals())\n",
        "\n",
        "                if dones[i]:\n",
        "                    if is_monitor_wrapped:\n",
        "                        # Atari wrapper can send a \"done\" signal when\n",
        "                        # the agent loses a life, but it does not correspond\n",
        "                        # to the true end of episode\n",
        "                        if \"episode\" in info.keys():\n",
        "                            # Do not trust \"done\" with episode endings.\n",
        "                            # Monitor wrapper includes \"episode\" key in info if environment\n",
        "                            # has been wrapped with it. Use those rewards instead.\n",
        "                            episode_rewards.append(info[\"episode\"][\"r\"])\n",
        "                            episode_lengths.append(info[\"episode\"][\"l\"])\n",
        "                            # my code\n",
        "                            # record images for completed ep\n",
        "                            # then reset img record\n",
        "                            episode_img.append(imgRecPerEnv[i])\n",
        "                            imgRecPerEnv[i] = []\n",
        "                            # Only increment at the real end of an episode\n",
        "                            episode_counts[i] += 1\n",
        "                    else:\n",
        "                        episode_rewards.append(current_rewards[i])\n",
        "                        episode_lengths.append(current_lengths[i])\n",
        "                        episode_counts[i] += 1\n",
        "                    current_rewards[i] = 0\n",
        "                    current_lengths[i] = 0\n",
        "\n",
        "        observations = new_observations\n",
        "\n",
        "        if render:\n",
        "            env.render()\n",
        "\n",
        "    mean_reward = np.mean(episode_rewards)\n",
        "    std_reward = np.std(episode_rewards)\n",
        "    if reward_threshold is not None:\n",
        "        assert mean_reward > reward_threshold, \"Mean reward below threshold: \" f\"{mean_reward:.2f} < {reward_threshold:.2f}\"\n",
        "    if return_episode_rewards:\n",
        "        return episode_rewards, episode_lengths, episode_img\n",
        "    return mean_reward, std_reward, episode_img"
      ],
      "metadata": {
        "id": "hD2h2XNIbT58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91987777-57d3-488a-c1e1-3fda972a1578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and record the videos, along with ep rew and ep lens.\n",
        "\n",
        "import pickle\n",
        "\n",
        "ep_reward, ep_len, imgRecPerEnv = evaluate_policy_andReturnRecording(model, vec_env, n_eval_episodes=100, return_episode_rewards=True)\n",
        "\n",
        "f_out = open('ep_reward.pkl', 'wb')\n",
        "pickle.dump(ep_reward, f_out)\n",
        "f_out.close()\n",
        "\n",
        "f_out = open('ep_len.pkl', 'wb')\n",
        "pickle.dump(ep_len, f_out)\n",
        "f_out.close()\n",
        "\n",
        "# This data object can be large > 10 GB\n",
        "# omit saving\n",
        "# f_out = open('imgRecPerEnv.pkl', 'wb')\n",
        "# pickle.dump(imgRecPerEnv, f_out)\n",
        "# f_out.close()\n",
        "\n",
        "\n",
        "# copy it there\n",
        "!cp ep_reward.pkl ./gdrive/MyDrive/models/evalPPO/ep_reward_100_noFrameSkip_try2.pkl\n",
        "!cp ep_len.pkl ./gdrive/MyDrive/models/evalPPO/ep_len_100_noFrameSkip_try2.pkl\n",
        "# !cp ep_len.pkl ./gdrive/MyDrive/models/evalPPO/ep_recording_100_noFrameSkip_try2.pkl"
      ],
      "metadata": {
        "id": "66enGKfwdQKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab41e0e3-4f71-4436-9efd-51149aaf3ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ep_reward)\n",
        "maxScoreIdx = max(enumerate(ep_reward),key=lambda x: x[1])[0]\n",
        "maxScore = ep_reward[maxScoreIdx]\n",
        "print(\"Max Score: \", maxScore)\n"
      ],
      "metadata": {
        "id": "8o2r4y6F9fZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e2a8f4-25ef-48fa-d52e-f7aa5f7c0937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Score:  24935.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "imageio.mimsave(\"space_invaders_ppo.gif\", [np.array(img) for i, img in enumerate(imgRecPerEnv[maxScoreIdx])], duration=31.25) #  `duration=20 ms` (1000 ms * 1/fps)"
      ],
      "metadata": {
        "id": "i4rrAhBPhC_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOc6MwpJPgx6JqD3OeeRvq/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}